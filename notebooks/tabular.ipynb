{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef11ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training interrupted by user.\n",
      "Episode 1/100, Reward: -248.2838709677308\n",
      "Episode 1/100, Reward: -248.2838709677308\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 184\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m     agent \u001b[38;5;241m=\u001b[39m CarRacingQL(episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 184\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(rewards)\n\u001b[0;32m    187\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRewards Over Episodes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 169\u001b[0m, in \u001b[0;36mCarRacingQL.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m rewards \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisodes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 169\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpisode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepisode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m     rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n",
      "Cell \u001b[1;32mIn[10], line 151\u001b[0m, in \u001b[0;36mCarRacingQL.run_episode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    148\u001b[0m next_obs, reward, done, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_obs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m cropped_obs \u001b[38;5;241m=\u001b[39m next_obs[:\u001b[38;5;28mint\u001b[39m(next_obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.88\u001b[39m), :, :]\n\u001b[0;32m    153\u001b[0m next_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(cropped_obs, obs_history, speed_history)\n",
      "Cell \u001b[1;32mIn[10], line 112\u001b[0m, in \u001b[0;36mCarRacingQL.render_frame\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    110\u001b[0m cropped \u001b[38;5;241m=\u001b[39m obs[:\u001b[38;5;28mint\u001b[39m(obs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.88\u001b[39m), :, :]\n\u001b[0;32m    111\u001b[0m surf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mmake_surface(cropped\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mget():\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m pygame\u001b[38;5;241m.\u001b[39mQUIT:\n",
      "\u001b[1;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import gymnasium as gym\n",
    "from collections import deque, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pygame\n",
    "ACTIONS = [\n",
    "    [-1.0, 0.0, 0.0],  # hard left (no gas)\n",
    "    [ 0.0, 0.0, 0.0],  # no action\n",
    "    [ 1.0, 0.0, 0.0],  # hard right (no gas)\n",
    "    [-1.0, 1.0, 0.0],  # hard left + gas\n",
    "    [ 0.0, 1.0, 0.0],  # straight + gas\n",
    "    [ 1.0, 1.0, 0.0],  # hard right + gas\n",
    "]\n",
    "\n",
    "class CarRacingQL:\n",
    "    def __init__(self, episodes=1000, state_bins=None, epsilon=0.1, alpha=0.1, gamma=0.9, render=True):\n",
    "        self.env = gym.make('CarRacing-v3', continuous=False, render_mode='rgb_array')\n",
    "        self.actions = [0, 1, 2,  3, 4]  # Discrete actions\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.episodes = episodes\n",
    "        self.render = render\n",
    "\n",
    "        self.state_bins = state_bins or [10] * 8  # Default to 8 features\n",
    "        self.Q_table = defaultdict(lambda: np.zeros(len(self.actions)))\n",
    "\n",
    "        if self.render:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((640, 480))\n",
    "\n",
    "    def auto_canny(self, image, sigma=0.33):\n",
    "        v = np.median(image)\n",
    "        lower = int(max(0, (1.0 - sigma) * v))\n",
    "        upper = int(min(255, (1.0 + sigma) * v))\n",
    "        return cv2.Canny(image, lower, upper)\n",
    "\n",
    "    def estimate_lane_edges(self, norm):\n",
    "        vertical_profile = np.mean(norm, axis=0)\n",
    "        threshold = 0.3\n",
    "        indices = np.where(vertical_profile > threshold)[0]\n",
    "        if len(indices) > 0:\n",
    "            return indices[0] / len(vertical_profile), indices[-1] / len(vertical_profile)\n",
    "        return 0.0, 1.0\n",
    "\n",
    "    def extract_features(self, obs, obs_history, speed_history):\n",
    "        car = self.env.unwrapped.car\n",
    "        vel_vec = car.hull.linearVelocity\n",
    "        speed = np.linalg.norm([vel_vec.x, vel_vec.y])\n",
    "        wheel_steering = car.wheels[0].steer / 0.6\n",
    "\n",
    "        speed_history.append(speed)\n",
    "        acceleration = (speed_history[-1] - speed_history[-2]) * 50.0 / 10.0 if len(speed_history) > 1 else 0.0\n",
    "        acceleration = np.clip(acceleration, -1.0, 1.0)\n",
    "\n",
    "        gray = cv2.cvtColor(obs, cv2.COLOR_RGB2GRAY)\n",
    "        resized = cv2.resize(gray, (64, 64))\n",
    "        edges = self.auto_canny(resized)\n",
    "\n",
    "        norm = resized / 255.0\n",
    "        half = norm.shape[1] // 2\n",
    "        left_sum, right_sum = np.sum(norm[:, :half]), np.sum(norm[:, half:])\n",
    "        center_offset = (right_sum - left_sum) / (left_sum + right_sum + 1e-5)\n",
    "\n",
    "        obs_history.append(norm)\n",
    "        curvature = np.mean([\n",
    "            np.abs(obs_history[i] - obs_history[i - 1]).mean()\n",
    "            for i in range(1, len(obs_history))\n",
    "        ]) if len(obs_history) == obs_history.maxlen else 0.0\n",
    "        curvature = np.clip(curvature * 5.0, 0.0, 1.0)\n",
    "\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, minLineLength=20, maxLineGap=10)\n",
    "        angles = [np.arctan2(y2 - y1, x2 - x1) for line in lines for x1, y1, x2, y2 in [line[0]]] if lines is not None else []\n",
    "        avg_lane_angle = np.mean(angles) if angles else 0.0\n",
    "\n",
    "        sky_color = np.array([120, 174, 255]) / 255.0\n",
    "        top_pixels = obs[:20, :, :] / 255.0\n",
    "        off_track = 0 if np.mean(np.linalg.norm(top_pixels - sky_color, axis=2) < 0.1) > 0.3 else 1\n",
    "\n",
    "        left_edge, right_edge = self.estimate_lane_edges(norm)\n",
    "\n",
    "        return [\n",
    "            center_offset,\n",
    "            curvature,\n",
    "            avg_lane_angle / np.pi,\n",
    "            min(speed / 100.0, 1.0),\n",
    "            acceleration,\n",
    "            float(off_track),\n",
    "            left_edge,\n",
    "            right_edge,\n",
    "            wheel_steering,\n",
    "        ]\n",
    "\n",
    "    # Discretize the state space based on the number of bins for each feature\n",
    "    # Each feature is discretized into a number of bins defined in self.state_bins\n",
    "    def discretize_state(self, features):\n",
    "        return tuple(np.digitize(f, np.linspace(-1, 1, b)) - 1 for f, b in zip(features, self.state_bins))\n",
    "\n",
    "    def epsilon_greedy(self, state):\n",
    "        return np.random.choice(self.actions) if np.random.rand() < self.epsilon else np.argmax(self.Q_table[state])\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, done):\n",
    "        max_future_q = np.max(self.Q_table[next_state])\n",
    "        current_q = self.Q_table[state][action]\n",
    "        target = reward if done else reward + self.gamma * max_future_q\n",
    "        self.Q_table[state][action] += self.alpha * (target - current_q)\n",
    "\n",
    "    def render_frame(self, obs):\n",
    "        cropped = obs[:int(obs.shape[0] * 0.88), :, :]\n",
    "        surf = pygame.surfarray.make_surface(cropped.swapaxes(0, 1))\n",
    "        self.screen.blit(pygame.transform.scale(surf, (640, 400)), (0, 0))\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                raise KeyboardInterrupt\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_q:\n",
    "                    raise KeyboardInterrupt\n",
    "\n",
    "        pygame.display.flip()\n",
    "        pygame.event.pump()\n",
    "\n",
    "\n",
    "    def run_episode(self):\n",
    "        obs, _ = self.env.reset()\n",
    "        obs = obs[:int(obs.shape[0] * 0.88), :, :]\n",
    "        obs_history = deque(maxlen=5)\n",
    "        speed_history = deque(maxlen=5)\n",
    "\n",
    "        features = self.extract_features(obs, obs_history, speed_history)\n",
    "        state = self.discretize_state(features)\n",
    "\n",
    "        done, total_reward = False, 0\n",
    "    \n",
    "        def skip_frames(env, obs, skip=50):\n",
    "            for _ in range(skip):\n",
    "                obs, _, terminated, truncated, _ = env.step(0)  # Use a valid action (e.g., no action)\n",
    "                if terminated or truncated:\n",
    "                    return obs, terminated or truncated\n",
    "            return obs, False\n",
    "        \n",
    "        obs, done = skip_frames(self.env, obs, skip=50)\n",
    "\n",
    "        try:\n",
    "            while not done:\n",
    "                action = self.epsilon_greedy(state)\n",
    "                next_obs, reward, done, _, _ = self.env.step(action)\n",
    "\n",
    "                if self.render:\n",
    "                    self.render_frame(next_obs)\n",
    "                cropped_obs = next_obs[:int(next_obs.shape[0] * 0.88), :, :]\n",
    "                next_features = self.extract_features(cropped_obs, obs_history, speed_history)\n",
    "                next_state = self.discretize_state(next_features)\n",
    "\n",
    "                self.update_q_value(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nTraining interrupted by user.\")\n",
    "        finally:\n",
    "            self.close()\n",
    "\n",
    "        return total_reward\n",
    "\n",
    "    def train(self):\n",
    "        rewards = []\n",
    "        for episode in range(1, self.episodes + 1):\n",
    "            reward = self.run_episode()\n",
    "            print(f\"Episode {episode}/{self.episodes}, Reward: {reward}\")\n",
    "            rewards.append(reward)\n",
    "            print(f\"Episode {episode}/{self.episodes}, Reward: {reward}\")\n",
    "            \n",
    "        return rewards\n",
    "\n",
    "    def close(self):\n",
    "        if self.render:\n",
    "            pygame.quit()\n",
    "        self.env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent = CarRacingQL(episodes=100, render=True)\n",
    "    rewards = agent.train()\n",
    "\n",
    "    plt.plot(rewards)\n",
    "    plt.title(\"Rewards Over Episodes\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Total Reward\")\n",
    "    plt.show()\n",
    "\n",
    "    agent.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmps499",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
